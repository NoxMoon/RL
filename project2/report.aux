\relax 
\@writefile{toc}{\contentsline {section}{\numberline {I}introduction to LunarLander}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Deep Q-Learning}{1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces $\epsilon $-greedy}}{1}}
\newlabel{algo:seq}{{1}{1}}
\newlabel{eq:tdtarget}{{4}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Double Q-Learning}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Double Deep Q-Learning}{2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Double Deep-Q Learning}}{2}}
\newlabel{algo:ddql}{{2}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Experiment Results}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Training Agent}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Effect of learning rate. Moving average reward of 1000 episodes for different $decay$ values during training process. $decay=0.995$, $\tau =0.001$, $\gamma =0.99$ for all runs. The moving average is evaluated with a window of 100 episodes.}}{3}}
\newlabel{fig:lr}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Effect of Hyperparameters}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Effect of epsilon\_decay. Moving average reward of 1000 episodes for different $decay$ values during training process. $\tau =0.001$, $lr=0.0005$, $\gamma =0.99$ for all runs. The moving average is evaluated with a window of 100 episodes.}}{3}}
\newlabel{fig:epsilon_decay}{{2}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Effect of $\tau $. moving average reward of 1000 episodes for different $\tau $ values during training process. $decay=0.995$, $lr=0.0005$, $\gamma =0.99$ for all runs. The moving average is evaluated with a window of 100 episodes.}}{3}}
\newlabel{fig:tau}{{3}{3}}
\bibstyle{IEEEtran}
\bibdata{reference}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Comparison between $\gamma =0.99$ (a) and $\gamma =1$ (b). Each graph shows the moving average reward of four independent runs of given $\gamma $ value, with $decay=0.995$, $lr=0.0005$, $\tau =0.001$. The difference between 4 runs of same $\gamma $ value comes from random seed settings. It is shown that $\gamma =0.99$ gives more stable learning curves.}}{4}}
\newlabel{fig:gamma}{{4}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Discussion}{4}}
